 Good evening, guys.
 Good evening.
 Hello.
 Do you choose the.
 Mr.
 Stage is all or not yet.
 I don't know.
 I choose it.
 Maybe to that.
 Let's go.
 Oh, so.
 Like sure.
 Today's the deadline.
 It's just the.
 By the way, do we have strict delays for homework, guys?
 No.
 I don't know.
 It's not that strict because I.
 I did.
 Yeah, it was.
 But I would suggest to find at least like 10 to 15 minutes every day.
 How I am.
 Because when it will come at the end.
 It will be like everything, you know.
 So at least I'm just trying to find 10 to 15 to 20 minutes doing doing like by small, small, small parts.
 I think.
 I'm more from this course or.
 I'm others.
 Any I think.
 Other courses I think didn't give you homework yet.
 Yeah.
 They give.
 Data.
 Data processing.
 They gave it gave.
 He gave yesterday.
 I think this file formats.
 I.
 I.
 Yes, they.
 I miss it.
 The classes.
 I will watch it.
 Hmm.
 Hello.
 Hello.
 All right.
 I have a question.
 I'm a feature.
 I have a question.
 I'm not sure you know where two days ago, and Google introduced quantum computers.
 Yeah.
 Our second lesson you said that there's a problem with the.
 Model because they have a resource problem and what will be in the future about it?
 Because the if Google, if we have, they have a quantum competitors.
 I mean, they have a huge results.
 Yeah, so that's really good, a situation.
 I don't know how they work, like only very general concept of these cubies.
 I've been studying quantum physics in university, like at least one year, probably two years, I can't remember.
 A lot of electronics works on quantum effects, so for example some staff allows the electrons to jump the barrier.
 They actually cannot jump, so they're tumbling through that.
 No one knows how it works, but it works and we use it in TVs and smartphones.
 That's it.
 Some kind of some kind of magic.
 It's still I think they should be some kind of scientific explanation that I don't know how these quantum computers work.
 I don't understand the concept of something having the value of zero and one at the same time, because like, okay.
 I can imagine that, but how about the storage, right?
 So if I talk about like HDD or SSD, any storage, so you need to write it.
 And you need to like you should be able to read it in the future.
 And the most fear like two fears I remember like from the community regarding quantum computers is, okay, if they are so like powerful and can make like much more like, I don't know, it's the same computer, it's per second, so what about the encryption, right?
 So RSA or any other encryption algorithm.
 So basically encryption works like modern encryption works on the very basic example, like, there are how it's called like one way function in math.
 I don't know how is an English.
 and the structure of the function.
 So the way, like, it's very easy to calculate this.
 For example, it's very easy to multiply it to prime integers and get the result.
 But it's super hard to understand, like, what are the integers you multiply if you received this result?
 And a lot of encryption is based on that, and actually Bitcoin is based on that.
 So Bitcoin has several, like, Bitcoin has a lot of protocols inside, like, technologies.
 And most of them, like, top tier encryption we have right now.
 So if Google can beat that, so they can possibly, like, hijack all the new bitcoins.
 Maybe they can rewrite the whole Bitcoin, like, the whole blockchain, like, in a day, and I didn't know, like, steal all the bitcoins from us.
 So a lot of, like, military applications, like all this encryption and networking.
 So I don't know.
 It's technically possible that the SASH technology can appear, but taking an account how much time and money and resources and smart people it takes to build SASH think.
 So maybe the first country which builds it, I mean, you know, like, who creates some kind of, like, snow crash, like, from Cyberpunk books, I don't know.
 So we'll see.
 At least, like, I know, like, from what I understand, like, IT history and technology history, like, all the new, like, top tier technologies, they have, like, two applications, like, the two industries, basically driving them fast in, like, making them broadly available is porn industry and military.
 So this is like two things, usually picking up the latest SASH and trying to get, like, money of that.
 And maybe one of them will pick it up.
 I don't know.
 Maybe military first.
 So I think, and they see the new applications of quantum stuff.
 Yeah, but from personal perspective, like being a human, like, I don't know, like, IT guys.
 So yeah, that's interesting.
 But unless I cannot benefit from that, I can, unless I cannot, like, earn money doing that.
 So it's inevitable for me, like, the sun, the sun just can stop.
 I don't know, like, okay.
 But example, because the earth rotates across the sun.
 So the earth can just stop rotating.
 And it will be infinite night for me.
 So I can't do anything about that.
 I can't do anything about rain.
 So what I can do is just to buy them braille, or I don't know, pray during stops sometimes.
 So in case I have the problem or some thing, I cannot influence, I think it's good not to worry about it.
 Because if you worry about something, you cannot change.
 That's bad.
 So you spend a lot of resources.
 And the other example will be nothing, like, for sure.
 So my plan is just read the news.
 I don't know, follow this agenda, but don't worry about it.
 Okay.
 Yeah, let's get down to business.
 So let me try to open my, open our schedule.
 I have to reboot my BC today.
 So I lost this X was pretty shit.
 Okay, this one.
 Okay, so the good news, good news, we are on track, right?
 And here, here we are meeting number five.
 So today we're going to discuss with the API and local installation.
 The bad news, I took a look at some of the frameworks, like two or three, maybe five, but not like very, very high level.
 I like the blog posts you guys made.
 So I like the pictures.
 And I think I will share some of my favorite pictures next time.
 So I assume I will need this weekend to check them and probably to add in the exact same marks or something like that.
 So just give me some time.
 But I haven't found any like critical problems there.
 So just remember to share the workflow, how you how you did that, like for the first task.
 So I need to see like what problems you've been using.
 And don't forget about the pictures.
 So the pictures are necessary for our blog post.
 So I think we're going to focus on that probably either on this lecture or this one.
 We're going to have time to review the homework.
 So today we're going to discuss the BC.
 And this is very, let me show this slide.
 So here are the slides for today.
 So what is the visper and why we're discussing that?
 So mostly when people discuss the generator for AI or AI in general, so a focus stone like LLAMs, I know like a pilot, functions and stuff like that.
 So everything that works with text, right?
 Because it has more application to the business when you work with text, but still, usually what is being forgotten is images and audio processing.
 Can't get in the images.
 I can't say this like easier to monetize this.
 So not to my business applications.
 So I know a lot of.
 I know a lot of cases where clients came to us like to do and ask to create something like I don't know, maybe I read over a hundred of cases.
 And only on the several of them related to image generation, but some of them.
 Like more modest, more of these cases are related to audio and one of the usual request is, okay, guys, we have 5,000 hours of recordings of, I don't know, meetings or customers calling us for the support.
 So we need to understand this data, right?
 So imagine you have a first line support like people calling like real users calling, describing the issue and the operators are just sharing.
 So what should you do to solve it?
 And you need to control it somehow, right?
 So you need to see what are the most of the questions or what are the answers.
 So is the client is happy or not, right?
 And for this case, you need to voice processing and processing the voice is actually very old technology.
 I don't remember how old it is, but like two things here, usually working is text-to-speech and speech-to-text.
 And if we check, I didn't know, like, let's check, Asia or Texas speech.
 Okay, it's a Y-speech now, all right, I got it.
 Everything is a Y-now.
 Let me check the pricing actually.
 DTS pricing.
 It's super cheap.
 It's super cheap.
 Okay, I think here.
 So this is.
 Okay, free tier, all right.
 Basically, all right, didn't need this one.
 So speech-to-text.
 So in order to transcript something like if you have a phone call, real time transcription, $1 per hour, that's too much.
 Okay, buy transcription.
 So if I have a lot of audio calls, I didn't know, like, one, I'm great.
 I can post them as a batch.
 And this will result me in 80 cents per hour.
 So not too much actually.
 Yeah, as usually like Microsoft has like very complicated, well, very complicated stuff for billing.
 So it's hard to understand how much you will spend.
 And here is like the text of speech.
 So basically to two directions, like from speech, you can extract text and from text, you can generate speech, right?
 And this is like the standard voice.
 I think this standard voice become neural, like during, like last year, because previously they had different.
 They had a different pricing.
 Like the standard voice is like this robotized voice, usually here when you call a bank or something.
 And neural voice is like more pleasant, more realistically, more naturally, not told.
 So right now, I don't think they should have some kind of like cheap voice, like this old cheap voice.
 Probably it's inside the easy way studio, but the trick is it's not expensive.
 Like I guess it's not expensive, right?
 So one billion characters is like, it's a lot.
 $15 for business.
 It's like, well, not too much, I think.
 And in case we have 1000 of like phone calls transcripted.
 So it will result as is only like less than $200.
 So that's acceptable for that.
 And they definitely use machine learning there, right?
 So because there's no way programmatically, like algorithmically to transcribe the speech.
 But still, the interesting thing here is it's also possible to use machine learning techniques and all this concept of token we've been discussing previously, right?
 In working with speech, in understanding this speech.
 And the project, the project I would like to show you this whisper.
 So let me find it should be here in the notes I put.
 Yeah, this one.
 It wasn't introduced very similar once the child GPC arrived, right?
 So.
 And just trying to recognize what was the time when charge IPT released.
 Okay.
 Chat.
 GPC.
 Released.
 Okay, November 30.
 All right, 2022.
 Yeah, so they introduced this per like couple of months before charge IPT into know what happens like.
 Do you remember this movie?
 So this one.
 So do you know this movie?
 It's kind of like popular from scientific perspective, but they they got the problem, right?
 So this is the cyber like not the cyberpunk, but probably like interesting science fiction.
 Take a look at the release years 1999.
 The problem is that in 1999.
 This movie gets out matrix.
 And that's why like everyone know about the matrix.
 It was like very successful movie.
 And this is the reason.
 Much more less people know that this movie thought is for even exists.
 If they are all easy like a year previous before matrix, so much more success.
 So the same is the whisper, right?
 So charge IPT release November of the team and whisper actually the same company opened here, but it was not so hyped.
 In September, as it become in November, right?
 So what they introduced is they actually been working like at the same time looks like.
 They've been working at the whisper and parallel like working with charge IPC, right?
 So they reused the same like not the same, but similar architecture like encoders, decoders and tokens to predict the tokens, but not from text, but from audio as well.
 So they just take a look at the audio, right?
 And in the paper, so they share like.
 This one.
 So they took.
 Six hundred.
 80,000 hours of multilingual.
 Audio.
 So they sliced it in 30 seconds.
 Time like steps, not steps, but chunks.
 And they trained the model, the trained the model against it using the same approach.
 They use for the GPT, so pretty the same like slice the data into some samples.
 Try to predict the tokens like compare with the result, learn, train the model and so on.
 So, and this results in a very interesting thing.
 Very high quality and I don't know if there are any model right now, which can be it's inequality of whisper.
 Because once it was released, it was like very high quality.
 They released another model.
 Couple of months ago, I think it's called whisper, but their architecture seems to stay to stay the same.
 So, and one more interesting thing here is it's completely open sourced.
 So you can download it and it doesn't require a lot of VRAM to run.
 So you can run it on the GPU.
 You can run it a bit slower on the CPU.
 And as far as it's like not large language model, it will perform like with acceptable acceptable speed.
 I've been running it at the CPU once and it works normally.
 So not so slow as the LLM.
 So we are not so interested in technical details and I don't understand them actually just to explain to you.
 But what we're interested in is actually we're interested in the result.
 So how it works and how I can use it.
 So how to use it.
 So you just install it as a Python package, but you need by touch.
 It's like why I mentioned the PyTorch previously.
 So in order to install it locally.
 So you must have the PyTorch and.
 And this is the command.
 It should be a PyTorch.
 Download probably now.
 Come on, where's download?
 Get started.
 Here install.
 Okay, like if you would like to try this per right or in future if you would like to work with PyTorch.
 So there's like two options here.
 So it doesn't matter which version you will be installing.
 You're going to see.
 The same table for every time like it's couple of years the same.
 So.
 If you installing it like in straightforward like recommended way.
 Like usually it's windows.
 Python, package, or people.
 Python.
 And here is like CUDA or CPU.
 And depending on what you will select.
 The URL will be different, right?
 So CUDA is the accelerated.
 Computing framework created by Nvidia as far as I remember by Nvidia.
 To run the computations on the GPU.
 And if you download and install this PyTorch.
 You will be running everything against the GPU.
 But if you do not have GPU, right?
 So you can install it.
 Without like just the CPU.
 And it will be the same by torch.
 It would work the same, but much more slow, right?
 But it will still work.
 So you need to prior to install the PyTorch.
 So first you need to Python.
 Next you need to select the CUDA version.
 So usually the later the better you just copy this and style.
 And actually I did that today because my PyTorch.
 Well, not PyTorch, but whisper failed around today.
 I've been preparing to the demo and I also have like the.
 Some files.
 Audio files.
 So and the problem is why.
 Facing them and you may face the same.
 So let me.
 Let me show you.
 So the problem with Python is that.
 Now like for.
 For modern applications, I use Nampai version 2.
 So Nampai is a framework is a library to working like with numbers in Python.
 And it's required by PyTorch.
 But this.
 This PyTorch and it's like implementation in whisper.
 Doesn't work with Nampai 2.
0.
 So it requires like old version.
 And that's that's kind of problem you may face as well.
 So what I did is actually I installed.
 Like virtual environment.
 So I created a virtual Python environment and downloaded once again.
 PyTorch.
 Whisper and all the stuff.
 So at least now it works right.
 So that's that's the problem you may face with working with any software.
 So I think that's the problem.
 So I think that's the problem.
 And I think that's the problem.
 At least I think they should be some kind of work around.
 But taking a look at how many people using the virtual environments.
 I think this is this is the acceptable work around.
 So getting back here.
 So what you need is just to install the library.
 And that's it.
 You can install it from source.
 But I prefer like this lazy option.
 And.
 It also requires FF impact.
 This is the most popular library to working with audio and video.
 So.
 And actually.
 This may be useful for you in future.
 So I know like working in development or.
 Just processing media like audio and video requires you to convert files from one format to another.
 Split them.
 I don't know change the beat rate and anything.
 So everything can be done with the FF impact.
 But FF impact is a command line interface like.
 It's a program which allows you to do.
 Everything.
 But without the user interface without the UI.
 But you can you can work with it programmatically.
 So for example, this is how you can convert from N before to.
 Av like the old format, right.
 And this is like the.
 The greatest software and the fastest solution right now.
 I think.
 So a lot of.
 Audio and video converting software use FF impact.
 So it will be necessary as well.
 If you would like to start with whisper.
 Because whisper will need to transform the.
 The data from one from a twin others.
 For example, in my example, I'm going to use.
 MP3.
 But in some cases, it may be one format or something like that.
 So this will need to try to transform from one format to another.
 And here are the models and languages.
 So as far as it's machine learning model, right.
 So you can pick up any.
 Model and getting back here.
 So remember, we've been discussing this like model card.
 And the.
 Quantization distillation and so on.
 So different models, right.
 So this is like 13 billion model.
 This is 70 billion model the same with whisper.
 So this model has 39 million parameters.
 It's tiny and it requires only one gigabyte of video.
 Ram like V.
 Ram.
 And it's very fast, right.
 So assuming the large model has like 1.
5 billion.
 To occupy 10 gigabytes of V.
 Ram and the speed is one like one X, right.
 So this one is 10, 10 times faster and turbo is 8 times faster.
 And that's a day they have large V to and large V 3.
 And what's more interesting here is the quality.
 So the quality here is measured in W.
 W-E-A-R, like word error rate.
 So it just evaluating how many words mispredicts how many words are wrong.
 And you can see the languages here.
 So depending on the dataset and probably the language structure, this really differs, right?
 So I'm not surprised this Spanish is the, has like, less errors than any other languages because Spanish, at least from my perspective, I know like a couple of words.
 And it's, it looks like very easy language, right?
 Like straightforward and kind of easy.
 Yeah, and some of the languages probably lacking the presence in the internet will result in like half of the words mispelled like Belarusian.
 I don't know, I think I need to, I know Belarusian language and I think I need to find some podcasts in Belarusian and try to feed it into the visper and check like it works.
 But this, this someone strange because 42 out of 100 agreed comparing to six in Ukrainian.
 So Belarusian and Ukrainian are super similar, super similar.
 So I can understand like 90% of Ukrainian.
 And Ukrainians understand 90% of Belarusian.
 Probably is the problem in the dataset, right?
 Okay, but in case like in most cases we're gonna work with English, right?
 So working with these languages are super cool.
 And common line users is pretty easy.
 So let's run the, let's run the example and for the example, I have the, I took the matrix movie and you know, like there is a scene, Agents meet a stock and it was more fused.
 Let me just matrix, Agents meet his, his delivering the speech about like the humans.
 I'm not sure you will be able to, to hear it because I'm using teams in, in browsers.
 So it's not desktop applications.
 So I can't share my audio, but here is like the, the Agents meet is interrogating more fused and he's delivering the speech like, I got the idea.
 So human beings are a virus and we, like the Agents are the cure.
 So I will drop you the link or you can just google it.
 And, and reconsider this is, I picked this sample because the like high quality speech and know any like music in background and something like that.
 So let me try to run this and check how it will work.
 So default whisperer.
 I just need to call whisper and pass the parameter as the data file.
 So right now is detecting the language.
 Isn't first or the second sent the language is detected to English.
 So you can do that actually, mainly you can specify the language and here is the output, right?
 So this is like the Smith is, discussing it, this is very precise.
 Actually, this is very precise.
 I think it's like, probably here we have the problems.
 Yeah, I think it's messing, it's messing something still.
 But I don't know what model I'm using.
 So let me call the, the usage.
 Okay, so a lot of things here.
 So we are interested in the model.
 So we can specify the model from here, right?
 So these are the available models.
 I don't know which one is the default, maybe small or base.
 So I have a lot of VRAM.
 So I can actually launch large model.
 So let's try with probably another model.
 And you can also specify the language explicitly.
 I don't think it will help us because it automatically recognized the business English.
 One more thing actually, very interesting thing.
 You can do with this.
 So here should be a parameter, which is called prompt.
 You find it.
 Tress, automation.
 Okay, model device, output, we're both.
 The ship a parameter, which is called something like a prompt.
 No.
 Yeah, this one initial prompt.
 So the trick is, so by default, it's not, but let's get back to the idea.
 So this per.
 So this per works with tokens, right?
 And everything like in this architecture, you can, you can pass the system message.
 So you can pass the system message and whisper.
 And I've been working once on English transcription task.
 So we decided to make.
 To transcribe the English assessments in other companies.
 So there is like an interviewer asking questions and the person replying.
 And one of the idea was to calculate the.
 I don't know how it's called like the world's like, when the person is thinking, like, parasite words.
 So it's not possible to do with just playing with Per.
 Hardly possible, but if you explicitly provide them in a prompt, it will recognize them.
 And also a lot of times in this dialogue, they were mentioned to a company name, EEPAM.
 And there is no such word in whisper data set.
 So that's why it was looking for a similar, but if you provide it in initial prompt, and it will like see the same token combination, it will just do not search for any other alternatives.
 So this is very powerful thing, like, I'm very underrated.
 Okay, so let's get back here and let's try the model.
 Let me try different models.
 And we're gonna see the performance like this speed.
 Let's try with tiny, smallest model.
 And let's check how fast it will work.
 Pretty fast.
 And let me try Turbo.
 Okay, pretty fast as well.
 I don't see a big difference in speed here, right?
 At least at this sample, the sample is on the one minute.
 No, okay, yeah.
 The final token was took the time and let me try large.
 So the large should give us the highest quality.
 Okay.
 Yeah, you see the difference.
 So large and turbo versus the tiny.
 So the tiny, you can just understand what's what's going on in this discussion.
 So if you don't care about particular worlds, if you just would like, I don't know, to summarize it in future and make some decision, like I didn't know sentiment analysis, something so maybe tiny is okay, but still that's a lot of questions as far as I see.
 But here the turbo and the large, so they work very effectively.
 All right.
 So and once I run every model, so it's getting downloaded.
 So I don't think I started small, so probably it will be downloading right now.
 No, no, it's already downloaded.
 I think yeah, so once I selected large first time, it started downloading all of this model, like one and a half gigabytes of model locally.
 So if you have a lot of files, I didn't know, million of hours.
 So what you just need, just need a PC.
 So you can use it in cloud, right?
 So let's check the pricing, open the icon.
 API pricing.
 So you can do that with API.
 Let me scroll to the whisper, fine tuning, create time, systems.
 Okay, images, audio models.
 Okay, so what we're gonna pay, we're gonna pay 0.
16 cents per minute.
 So let's, let me calculate one hour.
 Okay, well.
 So.
 0.
16 cents per minute.
 So it means one hour will cost us 36 cents.
 Yeah, so it means like 100 hours of transcription will result in 36 dollars.
 So this should be some point where it's cheaper to purchase hardware and run it on your hardware and save the hardware for yourself instead of sending to the open AI, right?
 Yeah, so in some cases it's more effective to do it on your own machine.
 I didn't like spend the night to create some Python scripts.
 And yeah, regarding Python, you can call it from Python as well.
 So it's Python library.
 So you can, you can use it from command line, but you can also, here is the command line usage.
 You can also import it.
 Load the model and transcribe your own data, just passing as the reference to the file, right?
 And here are the examples how you can do that with, with Python.
 Still, it has one problem, which probably be solved in some forks of the whisper, like whisper X and so on.
 The problem is it doesn't differentiate speakers.
 So you will not see the difference between speaker one and speaker two, right?
 So what I did in homework, I shared the file with you, where there is a difference between speaker one and speaker two.
 So here is no any difference, but the output formers may be different, right?
 So let me call the help once again.
 Here, output format, you can see, we have a lot of different output formers, TXT, VTT, SRT, T SVG zone, all.
 Let's try, let's try to run with all, but probably all is a default, right?
 So let me share.
 Oh, okay, yeah, all is a default.
 It means I already have all this information available.
 So let's check it out.
 If you like JSounds, you can run this, with me for a minute.
 Very good, right?